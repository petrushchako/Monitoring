# Splunk 9: Performing Basic Splunk Searches

## Introduction to Search in Splunk
### Course Objective
This course focuses entirely on **searching in Splunk**, a core functionality of the platform. It builds upon the knowledge from the first course, **Installing and Configuring Splunk**, and guides learners through hands-on search operations using real-world examples.

### Learning Path Overview
1. **Course 1**: Installing and Configuring Splunk
2. **Course 2**: Performing Basic Splunk Searches *(current course)*
3. **Course 3**: Building Dashboards and Reports

### Course Structure and Topics Covered
1. **Performing Basic Searches**
   * Understand the structure and purpose of a Splunk search.
   * Learn how to interact with the Splunk search interface.

2. **Field Search Basics**
   * Learn the foundational elements of field-based searching.
   * Navigate the Splunk interface to filter and refine data.

3. **Writing SPL Queries**
   * Get introduced to **Search Processing Language (SPL)**.
   * Write basic to intermediate SPL queries to extract insights from data.

4. **Transformative Searches**
   * Learn to reshape and enhance data presentation using transformation commands.
   * Use scenarios from Globomantics to apply transformations.

5. **Using Lookups**
   * Understand what lookups are and how to integrate them in searches.
   * A key topic for Splunk certification readiness.

6. **Beyond the Search**
   * Explore advanced Splunk capabilities and next learning steps.
   * Learn about career paths: Splunk admin, developer, user roles, and API integration.

<br><br><br>

## Searching Machine Data
### The Importance of Searching Machine-Generated Data
* **Machine-generated data** refers to logs, events, and metrics automatically created by systems, applications, and devices.
* Around **90% of enterprise data is machine-generated**, making it essential to have tools like Splunk to search, analyze, and extract meaningful insights.
* Searching through such data can feel like finding a **needle in a haystack**—there is massive volume and complexity, and no visual markers to guide the process.

<br>

### Real-World Use Case: Insider Threat Detection
* The instructor shares a personal experience working on an **insider threat detection application**.
* The goal was to identify potential internal security breaches proactively, rather than discovering them months later.
* Data sources included:
  * **Browser history**
  * **Firewall logs**
  * Activity from **50,000+ users**
* This resulted in an overwhelming volume of logs, showing the need for a scalable and intelligent search solution.
* **Splunk's value** lies in acting as an “easy button” to:
  * Ingest large data sets
  * Structure and index data
  * Enable rapid search and analysis

<br>

### Example Use Case: Globomantics Logs
* Dataset includes web access logs showing:
  * IP addresses
  * Browsers
  * Timestamps
* Even in a **small time window**, the data volume is significant.
* Over **longer periods (7–30 days)**, analyzing such logs manually becomes impractical.

<br>

### Sample Business Questions Answered by Splunk
1. **How many web hits per hour?**
2. **What browsers are most commonly used?**
   * Helps development teams optimize site compatibility.
3. **Which IP addresses are accessing the system?**
   * Useful for blacklisting, security auditing, and traffic analysis.

<br>

### Overview of Splunk Analytics Architecture
* **Indexer**:
  * Structures incoming data
  * Enables fast, indexed searches
* **Search Head**:
  * The user interface for executing searches
  * Pulls from indexed data
* **Forwarder**:
  * Lightweight agent on source systems (e.g., servers, firewalls)
  * Sends machine-generated data to the main Splunk instance

> In the course's development environment, **indexer, search head, and forwarder** are all hosted together for simplicity.

<br><br><br>

## Splunk Data Sets
### What Kind of Data Does Splunk Handle?
* **Primary Focus**: Machine-generated, semi-structured data.
* **Examples**:
  * Log files (e.g., system, firewall, access logs)
  * CSV, TSV (Comma/Tab Separated Values)
  * JSON and other structured text formats

> **Semi-structured** means the data has some structure (e.g., key-value pairs) but not fixed columns like relational databases.

<br>

### Why Machine-Generated Data Matters
* Over **90% of enterprise data** is generated by machines.
* Historically **underused** because of:
  * Massive volumes
  * Lack of easy tools to interpret it
* **Splunk** provides search and visualization capabilities to make this data usable.

<br>

### Data Sources Splunk Can Ingest
* **Server logs** (e.g., from application servers or syslogs)
* **Cloud platforms**:
  * AWS
  * Azure
  * Google Cloud Platform
* **End-user devices**:
  * Windows
  * Linux
  * macOS
* **IoT devices**:
  * Windmills
  * Solar panels
  * Smart appliances
> If it produces logs or outputs that can be parsed with regex, you can Splunk it.

<br>

### Hands-On Data in This Course
* **Sample Access Logs**:
  * Provided for Windows, Linux, and macOS users
* **Buttercup Games** (Splunk demo org):
  * Offers mock datasets for training
* **Eventgen Tool**:
  * Splunkbase add-on
  * Simulates real-time log generation for testing & app dev
  * Useful when static logs aren't enough

<br>

### Key Takeaway
> If you can apply **regular expressions** to it, you can **ingest and search it** in Splunk.


<br><br><br><hr><br>

## Understanding the Basics of Splunk Search
This section introduces **foundational Splunk search skills**, with a focus on **administrative responsibilities** that influence search capabilities.<br>As an admin or power user, **understanding roles, architecture, and lifecycle** decisions are essential for ensuring **efficient, secure, and compliant Splunk searches** at scale.


### Focus Areas:
1. **Troubleshooting Search Access**
   * Helping users who can’t search certain indexes
   * Diagnosing basic search issues

2. **Infrastructure’s Impact on Searches**
   * How storage architecture influences performance and access

<br>

### Module Breakdown
#### 1. **Understanding Splunk Roles**
* Overview of **user roles** and their permissions
* Live **demo** on:
  * Inspecting current roles
  * Modifying role-based access
* Understanding where roles are configured and stored

#### 2. **Data Storage in Splunk**
* Comparison of infrastructure setups:
  * **Traditional Splunk Architecture**
  * **SmartStore Architecture** (cloud-optimized storage tiering)

#### 3. **The Data Lifecycle**
* Managing Splunk at **petabyte-scale**
* Key topics:
  * **Data archiving**
  * **Cost-effective retention**
  * **Compliance** requirements
  * Ensuring archived data remains searchable


<br><br><br>


## Splunk Roles in Search
Roles are a critical component of managing **user access and functionality** in Splunk. When troubleshooting user issues like **"I can't search"** or **"Splunk is broken"**, the first area to check is **user roles and permissions**.

### Why Roles Matter
* Roles control **what data a user can access** and **what actions they can perform**.
* Every user is assigned a role that defines their **permissions** within the Splunk environment.

<br>

### Default Splunk Roles
#### 1. **User**
* Can **create and edit searches** for data they are allowed to access.
* Can **interact with saved searches** they own or are shared with them.
* Cannot edit shared objects or global alerts.

#### 2. **Power User**
* Inherits all permissions of a **User**.
* Can **edit shared objects** (like dashboards and alerts).
* Useful for team leads or advanced users who contribute shared insights.

#### 3. **Admin**
* Full administrative privileges:
  * Can **create new users**
  * **Assign roles and permissions**
  * **Access all data and system settings**
* Has control over indexes, apps, objects, and user configurations.

<br>

### Use Case Example
At a company like **Globomantics**, imagine:
* One index is for **Windows Admin Alerts**.
* Another index is for **Marketing Data**.

A user from the **marketing team** will not have access to Windows-related data if their role does not permit access to that index. If they complain they can't see a search result, it's likely a **permissions issue**, not a technical fault.


### Key Takeaways
* Roles are the **first checkpoint** in search access issues.
* Proper role assignment ensures **data isolation** and **security compliance**.
* Understanding roles helps administrators **maintain secure, efficient access control**.


<br><br><br>


## Data Storage in Splunk
### Data Ingestion and Indexing Workflow

When data enters Splunk—whether from infrastructure, applications, or access logs (e.g., from Globomantics)—it undergoes a specific ingestion and indexing process to make it searchable.

### The Role of the Index
* An **index** is where data is stored in Splunk after ingestion.
* Incoming data is **indexed**, which means it is transformed from raw format into **searchable events**.

### Indexing Steps in Splunk
1. **Metadata Creation**
   * Splunk extracts metadata from the raw data to improve searchability.
2. **Data Compression**
   * Compresses the data to:
     * Save storage space.
     * Speed up search performance.
3. **Data Indexing**
   * Data is indexed into searchable units, enabling fast retrieval using SPL.

### Example: Access Log Data
* Example input: A raw CSV access log with fields like IP address, date, request type, page accessed, and user agent.
* Splunk processes this into:
  * **Key-value pairs** for fields.
  * An **ingestion timestamp** separate from the original event timestamp.

> Note: There may be discrepancies between the event’s timestamp and the ingestion timestamp, especially if uploading archived data.

### Buckets: Splunk's File System for Data
* Splunk stores indexed data in directories called **buckets**.
* A **bucket** is a logical directory containing indexed files.
* **Data age** determines the bucket placement:
  * Newer data → recent buckets.
  * Older data → rolled into aging buckets.

#### Lifecycle of a Bucket
* Data is ingested and placed into an initial bucket (e.g., `bucket_1`).
* As it ages or the bucket fills up, the data moves to other buckets.
* Multiple buckets can exist per index.
* While **bucket management is transparent to users**, understanding it helps when discussing **data retention** and **search efficiency**.

<br><br><br>

## Bucket Management in Splunk
### Why Infrastructure Matters (Even in a Search Course)
Understanding Splunk infrastructure is essential because it directly impacts:
* **Query performance**
* **Storage cost optimization**
* **System scalability**

### Key Infrastructure Considerations
When designing your Splunk environment, ask:
* **How much data** are you ingesting? (e.g., 1 TB/day vs 1 PB/day)
* **How many users** and how intensive are the searches?
* **What are your performance** and **storage requirements**?
* **What is your growth projection** over time?
* **What compliance or retention rules** apply to your data?

<br>

### Splunk Bucket Lifecycle
Splunk stores indexed data in **buckets** representing different stages of the data's lifecycle:

| Bucket Type | Typical Usage Duration | Storage Type                     | Performance        |
| ----------- | ---------------------- | -------------------------------- | ------------------ |
| **Hot**     | \~24 hours             | Active local storage             | High               |
| **Warm**    | Up to \~3 months       | Local fast storage               | High               |
| **Cold**    | >3 months              | Slower/cheaper storage           | Low                |
| **Frozen**  | Beyond retention limit | Archived (e.g., NAS, S3, Hadoop) | Very Low (Offline) |

> Durations are **configurable** based on your data volume and environment.

#### Frozen Bucket Use Cases:
* **Compliance** (e.g., HIPAA, SOX, SEC)
* Long-term archive for regulated industries
* Can be **re-thawed** for search if needed

<br>

### Performance vs Cost
* **Hot/Warm Buckets**:
  * High-speed storage
  * Optimized for fast searches
* **Cold Buckets**:
  * Lower-cost storage
  * Slower searches
* **Frozen Buckets**:
  * Archived or external storage
  * Restored only when needed

> You must plan carefully if reports often query older (cold/frozen) data.

<br>

## Splunk SmartStore: Modern Storage Architecture
### Traditional Splunk Architecture
* Individual hot, warm, cold, and frozen buckets
* Data stored on local disks

### SmartStore (Introduced in 2018)
* Designed for **simplified architecture** and **cloud-scale object storage**
* Supports S3-compatible object stores
* Storage divided into:
  * **Hot Cache** (\~7–10 days of recent data)
  * **Cold Cache** (older data tiered to object store)

| Tier           | Description                          | Storage                 |
| -------------- | ------------------------------------ | ----------------------- |
| **Hot Cache**  | Active + recent data (no warm split) | High-speed local        |
| **Cold Cache** | Long-term, slower, cheaper storage   | Object store (e.g., S3) |

> Queries outside the hot cache (cold searches) **may perform slowly**. Query optimization and caching strategy are critical.

<br>

### Choosing Between Traditional and SmartStore
* **New Splunk deployments** often default to **SmartStore**.
* Revisit architecture periodically as your needs evolve.
* SmartStore reduces cost but requires:
  * Consideration for report/query performance
  * Fine-tuning of cache size and aging policies

<br><br><br><hr><br>

## Using Field Searches for Splunk
This section introduces **field-based search techniques** in Splunk and emphasizes how to **interact with the UI**, **leverage the sidebar**, and **craft efficient queries** using proper syntax.

### Overview of the Module Breakdown
1. **Explore the Search Bar and Timeline**
   * Understand the **differences** between the search bar and timeline panel.
   * Learn **when and how** to use each for analyzing events.

2. **Define Field Operators in Splunk Search**
   * Learn about common **search operators**:
     * Comparison: `>`, `<`, `=`, `!=`
     * Boolean: `AND`, `OR`, `NOT`
     * Wildcards: `*`
   * Apply operators to **narrow down** and **target** specific results.

3. **Navigate the Splunk Sidebar**
   * Use the **Fields sidebar** to:
     * Discover **interesting fields**
     * View **top values**
     * Use **click-to-filter** options for quicker refinement

4. **Analyze Search Field Results**
   * Examine field data for **patterns and trends**
   * Use field values to **drill down** into more relevant subsets

5. **Discuss Best Practices for Splunk Searches**
   * Importance of:
     * Efficient field targeting
     * Minimizing wildcard usage on the **left side** of search terms
     * Leveraging indexed fields for faster performance
     * Structuring searches to return results quickly and with low resource usage

<br><br><br>


