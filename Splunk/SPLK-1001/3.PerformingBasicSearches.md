# Splunk 9: Performing Basic Splunk Searches

## Introduction to Search in Splunk
### Course Objective
This course focuses entirely on **searching in Splunk**, a core functionality of the platform. It builds upon the knowledge from the first course, **Installing and Configuring Splunk**, and guides learners through hands-on search operations using real-world examples.

### Learning Path Overview
1. **Course 1**: Installing and Configuring Splunk
2. **Course 2**: Performing Basic Splunk Searches *(current course)*
3. **Course 3**: Building Dashboards and Reports

### Course Structure and Topics Covered
1. **Performing Basic Searches**
   * Understand the structure and purpose of a Splunk search.
   * Learn how to interact with the Splunk search interface.

2. **Field Search Basics**
   * Learn the foundational elements of field-based searching.
   * Navigate the Splunk interface to filter and refine data.

3. **Writing SPL Queries**
   * Get introduced to **Search Processing Language (SPL)**.
   * Write basic to intermediate SPL queries to extract insights from data.

4. **Transformative Searches**
   * Learn to reshape and enhance data presentation using transformation commands.
   * Use scenarios from Globomantics to apply transformations.

5. **Using Lookups**
   * Understand what lookups are and how to integrate them in searches.
   * A key topic for Splunk certification readiness.

6. **Beyond the Search**
   * Explore advanced Splunk capabilities and next learning steps.
   * Learn about career paths: Splunk admin, developer, user roles, and API integration.

<br><br><br>

## Searching Machine Data
### The Importance of Searching Machine-Generated Data
* **Machine-generated data** refers to logs, events, and metrics automatically created by systems, applications, and devices.
* Around **90% of enterprise data is machine-generated**, making it essential to have tools like Splunk to search, analyze, and extract meaningful insights.
* Searching through such data can feel like finding a **needle in a haystack**—there is massive volume and complexity, and no visual markers to guide the process.

<br>

### Real-World Use Case: Insider Threat Detection
* The instructor shares a personal experience working on an **insider threat detection application**.
* The goal was to identify potential internal security breaches proactively, rather than discovering them months later.
* Data sources included:
  * **Browser history**
  * **Firewall logs**
  * Activity from **50,000+ users**
* This resulted in an overwhelming volume of logs, showing the need for a scalable and intelligent search solution.
* **Splunk's value** lies in acting as an “easy button” to:
  * Ingest large data sets
  * Structure and index data
  * Enable rapid search and analysis

<br>

### Example Use Case: Globomantics Logs
* Dataset includes web access logs showing:
  * IP addresses
  * Browsers
  * Timestamps
* Even in a **small time window**, the data volume is significant.
* Over **longer periods (7–30 days)**, analyzing such logs manually becomes impractical.

<br>

### Sample Business Questions Answered by Splunk
1. **How many web hits per hour?**
2. **What browsers are most commonly used?**
   * Helps development teams optimize site compatibility.
3. **Which IP addresses are accessing the system?**
   * Useful for blacklisting, security auditing, and traffic analysis.

<br>

### Overview of Splunk Analytics Architecture
* **Indexer**:
  * Structures incoming data
  * Enables fast, indexed searches
* **Search Head**:
  * The user interface for executing searches
  * Pulls from indexed data
* **Forwarder**:
  * Lightweight agent on source systems (e.g., servers, firewalls)
  * Sends machine-generated data to the main Splunk instance

> In the course's development environment, **indexer, search head, and forwarder** are all hosted together for simplicity.

<br><br><br>

## Splunk Data Sets
### What Kind of Data Does Splunk Handle?
* **Primary Focus**: Machine-generated, semi-structured data.
* **Examples**:
  * Log files (e.g., system, firewall, access logs)
  * CSV, TSV (Comma/Tab Separated Values)
  * JSON and other structured text formats

> **Semi-structured** means the data has some structure (e.g., key-value pairs) but not fixed columns like relational databases.

<br>

### Why Machine-Generated Data Matters
* Over **90% of enterprise data** is generated by machines.
* Historically **underused** because of:
  * Massive volumes
  * Lack of easy tools to interpret it
* **Splunk** provides search and visualization capabilities to make this data usable.

<br>

### Data Sources Splunk Can Ingest
* **Server logs** (e.g., from application servers or syslogs)
* **Cloud platforms**:
  * AWS
  * Azure
  * Google Cloud Platform
* **End-user devices**:
  * Windows
  * Linux
  * macOS
* **IoT devices**:
  * Windmills
  * Solar panels
  * Smart appliances
> If it produces logs or outputs that can be parsed with regex, you can Splunk it.

<br>

### Hands-On Data in This Course
* **Sample Access Logs**:
  * Provided for Windows, Linux, and macOS users
* **Buttercup Games** (Splunk demo org):
  * Offers mock datasets for training
* **Eventgen Tool**:
  * Splunkbase add-on
  * Simulates real-time log generation for testing & app dev
  * Useful when static logs aren't enough

<br>

### Key Takeaway
> If you can apply **regular expressions** to it, you can **ingest and search it** in Splunk.